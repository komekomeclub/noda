<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Android Voice Recorder</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { touch-action: manipulation; }
        /* èª­ã¿ã‚„ã™ãã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š */
        body { font-family: sans-serif; }
    </style>
</head>
<body class="bg-slate-100 h-screen flex flex-col p-4 text-slate-800">

    <header class="mb-4 text-center">
        <h1 class="text-xl font-bold text-slate-700">æ–‡å­—èµ·ã“ã— ï¼† ç„¡éŸ³ã‚«ãƒƒãƒˆ</h1>
        <p class="text-xs text-slate-500">Android Chromeå°‚ç”¨ç‰ˆ</p>
    </header>

    <div class="bg-white p-3 rounded-lg shadow-sm mb-4 flex justify-between items-center">
        <label class="text-sm font-bold">è¨€èª:</label>
        <select id="langSelect" class="border rounded p-2 text-sm bg-slate-50 outline-none">
            <option value="ja-JP" selected>æ—¥æœ¬èª</option>
            <option value="en-US">English</option>
        </select>
    </div>

    <div class="flex-grow bg-white rounded-lg shadow-sm p-4 mb-4 overflow-y-auto border border-slate-200 relative min-h-[200px]">
        <div id="recordingIndicator" class="absolute top-3 right-3 flex items-center gap-2 hidden">
            <span class="animate-ping absolute inline-flex h-3 w-3 rounded-full bg-red-400 opacity-75"></span>
            <span class="relative inline-flex rounded-full h-3 w-3 bg-red-500"></span>
            <span class="text-xs text-red-500 font-bold">éŒ²éŸ³ä¸­</span>
        </div>
        <div id="transcript" class="text-lg leading-relaxed whitespace-pre-wrap text-slate-700 h-full">
            <span class="text-slate-400 text-sm">ã“ã“ã«æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™...</span>
        </div>
    </div>

    <div id="playerArea" class="hidden mb-4 bg-blue-50 p-3 rounded-lg border border-blue-200">
        <div class="flex justify-between items-end mb-2">
            <p class="text-xs text-blue-800 font-bold">ç„¡éŸ³ã‚«ãƒƒãƒˆæ¸ˆã¿éŸ³å£°:</p>
            <a id="downloadLink" class="text-xs text-blue-600 underline font-bold px-2">ä¿å­˜ (WAV)</a>
        </div>
        <audio id="audioPlayer" controls class="w-full h-10"></audio>
    </div>

    <div class="grid grid-cols-2 gap-4 pb-2">
        <button id="recordBtn" class="bg-red-500 active:bg-red-600 text-white font-bold py-4 rounded-xl shadow-md flex flex-col items-center justify-center transition-transform active:scale-95">
            <span class="text-2xl mb-1">ğŸ™ï¸</span>
            <span>éŒ²éŸ³é–‹å§‹</span>
        </button>
        <button id="stopBtn" disabled class="bg-gray-300 text-gray-500 font-bold py-4 rounded-xl shadow-md flex flex-col items-center justify-center transition-transform active:scale-95">
            <span class="text-2xl mb-1">â¹ï¸</span>
            <span>åœæ­¢ãƒ»å‡¦ç†</span>
        </button>
    </div>

    <div id="logMessage" class="text-center text-xs text-slate-400 h-4"></div>

<script>
    // --- Androidå‘ã‘è¨­å®š ---
    const MIME_TYPE = 'audio/webm'; // Android Chromeæ¨™æº–

    // UIè¦ç´ 
    const recordBtn = document.getElementById('recordBtn');
    const stopBtn = document.getElementById('stopBtn');
    const transcriptEl = document.getElementById('transcript');
    const langSelect = document.getElementById('langSelect');
    const indicator = document.getElementById('recordingIndicator');
    const playerArea = document.getElementById('playerArea');
    const audioPlayer = document.getElementById('audioPlayer');
    const downloadLink = document.getElementById('downloadLink');
    const logMessage = document.getElementById('logMessage');

    // å¤‰æ•°
    let recognition;
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;

    // åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        alert("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯æ–‡å­—èµ·ã“ã—ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚");
    }

    // ã‚¤ãƒ™ãƒ³ãƒˆ
    recordBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);

    // --- 1. éŒ²éŸ³ï¼†æ–‡å­—èµ·ã“ã—é–‹å§‹ ---
    async function startRecording() {
        // UIãƒªã‚»ãƒƒãƒˆ
        transcriptEl.textContent = "";
        audioChunks = [];
        playerArea.classList.add('hidden');
        log("ãƒã‚¤ã‚¯æº–å‚™ä¸­...");

        try {
            // ãƒã‚¤ã‚¯å–å¾—
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            // A. éŸ³å£°èªè­˜ (SpeechRecognition)
            recognition = new SpeechRecognition();
            recognition.lang = langSelect.value;
            recognition.continuous = true;
            recognition.interimResults = true;

            recognition.onresult = (event) => {
                let finalTxt = '';
                let interimTxt = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTxt += event.results[i][0].transcript + '\n';
                    } else {
                        interimTxt += event.results[i][0].transcript;
                    }
                }
                // çµæœè¡¨ç¤ºï¼ˆç¢ºå®šåˆ†ï¼‹æœªç¢ºå®šåˆ†ï¼‰
                // æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ ã§ã¯ãªãã€å¸¸ã«å…¨ä½“ã‚’æç”»ã™ã‚‹æ–¹å¼ã§åŒæœŸã‚ºãƒ¬ã‚’é˜²ã
                const allTranscript = Array.from(event.results)
                    .map(r => r[0].transcript + (r.isFinal ? '\n' : ''))
                    .join('');
                
                transcriptEl.textContent = allTranscript;
                transcriptEl.scrollTop = transcriptEl.scrollHeight;
            };

            recognition.onend = () => {
                if (isRecording) recognition.start(); // æ„å›³ã—ãªã„åœæ­¢å¯¾ç­–
            };
            recognition.start();

            // B. éŒ²éŸ³ (MediaRecorder)
            mediaRecorder = new MediaRecorder(stream, { mimeType: MIME_TYPE });
            mediaRecorder.ondataavailable = e => {
                if (e.data.size > 0) audioChunks.push(e.data);
            };
            mediaRecorder.start();

            // UIæ›´æ–°
            isRecording = true;
            indicator.classList.remove('hidden');
            toggleButtons(true);
            log("éŒ²éŸ³ä¸­...");

        } catch (err) {
            console.error(err);
            alert("ãƒã‚¤ã‚¯ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: " + err.message);
        }
    }

    // --- 2. åœæ­¢ï¼†å‡¦ç†å®Ÿè¡Œ ---
    function stopRecording() {
        if (!isRecording) return;
        isRecording = false;
        log("å‡¦ç†ä¸­...ãŠå¾…ã¡ãã ã•ã„");

        // åœæ­¢å‡¦ç†
        recognition.stop();
        mediaRecorder.stop();
        
        // éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒç¢ºå®šã—ãŸã‚‰å‡¦ç†é–‹å§‹
        mediaRecorder.onstop = async () => {
            const blob = new Blob(audioChunks, { type: MIME_TYPE });
            
            // ç„¡éŸ³å‰Šé™¤å‡¦ç†ã¸
            try {
                const processedUrl = await processSilence(blob);
                
                // ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è¨­å®š
                audioPlayer.src = processedUrl;
                downloadLink.href = processedUrl;
                downloadLink.download = `rec_${new Date().getTime()}.wav`;
                
                playerArea.classList.remove('hidden');
                log("å®Œäº†");
            } catch (e) {
                console.error(e);
                alert("éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: " + e.message);
                // å¤±æ•—æ™‚ã¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                audioPlayer.src = URL.createObjectURL(blob);
                playerArea.classList.remove('hidden');
            }
        };

        // UIæ›´æ–°
        indicator.classList.add('hidden');
        toggleButtons(false);
    }

    // --- 3. ç„¡éŸ³å‰Šé™¤ãƒ­ã‚¸ãƒƒã‚¯ (Web Audio API) ---
    async function processSilence(blob) {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        const rawData = audioBuffer.getChannelData(0); // ãƒ¢ãƒãƒ©ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
        const sampleRate = audioBuffer.sampleRate;
        
        // è¨­å®š: é–¾å€¤ã¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        const threshold = 0.05; // éŸ³é‡é–¾å€¤ (0.05ãã‚‰ã„ãŒé›‘éŸ³ã‚’æ‹¾ã‚ãšé©å½“)
        const padding = 0.2;    // æ®‹ã™ä½™ç™½(ç§’)
        const paddingSamples = padding * sampleRate;

        // æœ‰éŸ³åŒºé–“ã®æ¤œå‡º
        const activeRanges = [];
        let start = null;

        for (let i = 0; i < rawData.length; i += 100) { // é–“å¼•ã„ã¦é«˜é€ŸåŒ–
            const val = Math.abs(rawData[i]);
            if (val > threshold) {
                if (start === null) start = Math.max(0, i - paddingSamples);
            } else {
                if (start !== null) {
                    // ç„¡éŸ³ãŒã—ã°ã‚‰ãç¶šã„ãŸã‚‰åŒºé–“çµ‚äº†ã¨ã¿ãªã™ç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯
                    // ã“ã“ã§ã¯ãƒ«ãƒ¼ãƒ—ã”ã¨ã«åˆ¤å®šã›ãšã€å¾Œå‡¦ç†ã§ãƒãƒ¼ã‚¸ã™ã‚‹æ–¹å¼ã‚’ã¨ã‚‹ãŸã‚
                    // å˜ç´”ã«ã€Œé–¾å€¤è¶…ãˆã€ã‚’è¦‹ã¤ã‘ã‚‹ã ã‘ã§ã‚ˆã„ãŒã€
                    // ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œé–¾å€¤ã‚’è¶…ãˆãŸã‚‰ãã®å‘¨è¾ºã‚’æœ‰åŠ¹ã€ã¨ã™ã‚‹
                }
            }
        }
        
        // æ­£ç¢ºãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼šã™ã¹ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’èµ°æŸ»ã—ã¦åŒºé–“ã‚’çµåˆ
        let isVoice = false;
        let lastVoiceIndex = 0;
        let ranges = [];
        
        // ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤ç¢ºå®Ÿãªãƒ­ã‚¸ãƒƒã‚¯ï¼š
        // 1. é–¾å€¤ã‚’è¶…ãˆã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’ã™ã¹ã¦è¦‹ã¤ã‘ã‚‹
        // 2. ãã®ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å‰å¾Œ paddingSamples åˆ†ã‚’ã€Œæœ‰åŠ¹ã€ã¨ã—ã¦ãƒãƒ¼ã‚¯ã™ã‚‹
        // 3. æœ‰åŠ¹ãªéƒ¨åˆ†ã ã‘ã‚’æŠ½å‡ºã—ã¦çµåˆã™ã‚‹
        
        // ãƒã‚¹ã‚¯é…åˆ—ã‚’ä½œæˆ (0:ç„¡éŸ³, 1:æœ‰éŸ³) - ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚Uint8Array
        const mask = new Uint8Array(rawData.length);
        
        for (let i = 0; i < rawData.length; i++) {
            if (Math.abs(rawData[i]) > threshold) {
                // å‰å¾Œã‚’1ã§åŸ‹ã‚ã‚‹
                let s = Math.max(0, i - paddingSamples);
                let e = Math.min(rawData.length, i + paddingSamples);
                // ç¯„å›²åŸ‹ã‚ï¼ˆãƒ«ãƒ¼ãƒ—ã ã¨é‡ã„ã®ã§ã€é–‹å§‹ç‚¹ã¨çµ‚äº†ç‚¹ã ã‘ç®¡ç†ã—ã¦å¾Œã§ã‚¹ã‚¤ãƒ¼ãƒ—ã‚‚å¯ã ãŒã€
                // JSã®fillã¯é«˜é€Ÿãªã®ã§ã“ã“ã§ã¯éƒ½åº¦fillã—ãªã„ã‚ˆã†å·¥å¤«ã™ã‚‹ï¼‰
                
                // æ„šç›´ã ãŒç¢ºå®Ÿã«: æœ‰åŠ¹åŒºé–“ã®start/endãƒªã‚¹ãƒˆã‚’ä½œã‚‹
                ranges.push([s, e]);
                i = e; // ã‚¹ã‚­ãƒƒãƒ—
            }
        }

        // åŒºé–“ã®ãƒãƒ¼ã‚¸
        if (ranges.length === 0) return URL.createObjectURL(blob); // å…¨ã¦ç„¡éŸ³ã®å ´åˆ

        let merged = [ranges[0]];
        for (let i = 1; i < ranges.length; i++) {
            let last = merged[merged.length - 1];
            let current = ranges[i];
            if (current[0] < last[1]) {
                last[1] = Math.max(last[1], current[1]);
            } else {
                merged.push(current);
            }
        }

        // æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã®é•·ã•ã‚’è¨ˆç®—
        let totalLen = merged.reduce((sum, r) => sum + (r[1] - r[0]), 0);
        
        // æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ä½œæˆ
        const newBuffer = audioContext.createBuffer(1, totalLen, sampleRate);
        const newData = newBuffer.getChannelData(0);
        
        let offset = 0;
        merged.forEach(r => {
            const len = r[1] - r[0];
            // éƒ¨åˆ†é…åˆ—ã‚’ã‚³ãƒ”ãƒ¼
            newData.set(rawData.subarray(r[0], r[1]), offset);
            offset += len;
        });

        return bufferToWave(newBuffer, totalLen);
    }

    // --- AudioBuffer -> WAV å¤‰æ› ---
    function bufferToWave(abuffer, len) {
        let numOfChan = 1;
        let length = len * numOfChan * 2 + 44;
        let buffer = new ArrayBuffer(length);
        let view = new DataView(buffer);
        let channels = [], i, sample;
        let offset = 0;
        let pos = 0;

        // WAVãƒ˜ãƒƒãƒ€ãƒ¼
        setUint32(0x46464952); // "RIFF"
        setUint32(length - 8); // file length - 8
        setUint32(0x45564157); // "WAVE"
        setUint32(0x20746d66); // "fmt "
        setUint32(16); // length = 16
        setUint16(1); // PCM
        setUint16(numOfChan);
        setUint32(abuffer.sampleRate);
        setUint32(abuffer.sampleRate * 2 * numOfChan);
        setUint16(numOfChan * 2);
        setUint16(16); // 16-bit
        setUint32(0x61746164); // "data"
        setUint32(length - pos - 4);

        // ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
        let channelData = abuffer.getChannelData(0);
        while(pos < len) {
            sample = Math.max(-1, Math.min(1, channelData[pos])); 
            sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767)|0; 
            view.setInt16(44 + offset, sample, true); 
            offset += 2;
            pos++;
        }

        return URL.createObjectURL(new Blob([buffer], {type: "audio/wav"}));

        function setUint16(data) { view.setUint16(pos, data, true); pos += 2; }
        function setUint32(data) { view.setUint32(pos, data, true); pos += 4; }
    }

    // UIåˆ¶å¾¡ãƒ˜ãƒ«ãƒ‘ãƒ¼
    function toggleButtons(isRec) {
        if(isRec) {
            recordBtn.disabled = true;
            recordBtn.classList.replace('bg-red-500', 'bg-slate-300');
            stopBtn.disabled = false;
            stopBtn.classList.replace('bg-gray-300', 'bg-blue-600');
            stopBtn.classList.replace('text-gray-500', 'text-white');
        } else {
            recordBtn.disabled = false;
            recordBtn.classList.replace('bg-slate-300', 'bg-red-500');
            stopBtn.disabled = true;
            stopBtn.classList.replace('bg-blue-600', 'bg-gray-300');
            stopBtn.classList.replace('text-white', 'text-gray-500');
        }
    }
    
    function log(msg) {
        logMessage.textContent = msg;
    }
</script>
</body>
</html>
