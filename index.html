<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Voice Recorder</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* iOSã§ã®ã‚¿ãƒƒãƒ—é…å»¶å¯¾ç­–ãªã© */
        body { touch-action: manipulation; }
    </style>
</head>
<body class="bg-gray-100 h-screen flex flex-col p-4 text-gray-800">

    <header class="mb-4 text-center">
        <h1 class="text-xl font-bold text-gray-700">æ–‡å­—èµ·ã“ã— ï¼† ç„¡éŸ³ã‚«ãƒƒãƒˆ</h1>
    </header>

    <div class="bg-white p-3 rounded-lg shadow mb-4 flex justify-between items-center">
        <label class="text-sm font-semibold">è¨€èªé¸æŠ:</label>
        <select id="langSelect" class="border rounded p-1 text-sm bg-gray-50">
            <option value="ja-JP" selected>æ—¥æœ¬èª</option>
            <option value="en-US">English</option>
            <option value="zh-CN">ä¸­æ–‡</option>
        </select>
    </div>

    <div class="flex-grow bg-white rounded-lg shadow p-3 mb-4 overflow-y-auto border border-gray-200 relative">
        <div id="status" class="absolute top-2 right-2 text-xs text-red-500 font-bold hidden">â— éŒ²éŸ³ä¸­...</div>
        <p id="transcript" class="text-lg leading-relaxed whitespace-pre-wrap text-gray-600">ã“ã“ã«æ–‡å­—èµ·ã“ã—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™...</p>
    </div>

    <div id="playerArea" class="hidden mb-4">
        <p class="text-xs text-gray-500 mb-1">ç„¡éŸ³ã‚«ãƒƒãƒˆæ¸ˆã¿éŸ³å£°:</p>
        <audio id="audioPlayer" controls class="w-full h-10"></audio>
    </div>

    <div class="grid grid-cols-2 gap-4 pb-4">
        <button id="recordBtn" class="bg-red-500 hover:bg-red-600 text-white font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center transition active:scale-95">
            <span class="text-2xl mb-1">ğŸ™ï¸</span>
            <span>éŒ²éŸ³é–‹å§‹</span>
        </button>
        <button id="stopBtn" disabled class="bg-gray-300 text-gray-500 font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center transition active:scale-95">
            <span class="text-2xl mb-1">â¹ï¸</span>
            <span>åœæ­¢ãƒ»å†ç”Ÿ</span>
        </button>
    </div>

<script>
    // --- å¤‰æ•°å®šç¾© ---
    let recognition;
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    
    // UIè¦ç´ 
    const recordBtn = document.getElementById('recordBtn');
    const stopBtn = document.getElementById('stopBtn');
    const transcriptEl = document.getElementById('transcript');
    const langSelect = document.getElementById('langSelect');
    const statusEl = document.getElementById('status');
    const playerArea = document.getElementById('playerArea');
    const audioPlayer = document.getElementById('audioPlayer');

    // Web Speech APIã®äº’æ›æ€§ãƒã‚§ãƒƒã‚¯
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        alert("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chromeã¾ãŸã¯Safariã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚");
    }

    // --- ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ ---
    recordBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);

    // --- ãƒ¡ã‚¤ãƒ³å‡¦ç†: éŒ²éŸ³é–‹å§‹ ---
    async function startRecording() {
        // åˆæœŸåŒ–
        transcriptEl.textContent = "";
        audioChunks = [];
        playerArea.classList.add('hidden');
        
        try {
            // 1. ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å–å¾—
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            
            // 2. éŸ³å£°éŒ²éŸ³ã®é–‹å§‹ (MediaRecorder)
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };
            mediaRecorder.start();

            // 3. æ–‡å­—èµ·ã“ã—ã®é–‹å§‹ (SpeechRecognition)
            recognition = new SpeechRecognition();
            recognition.lang = langSelect.value;
            recognition.continuous = true; // é€£ç¶šèªè­˜
            recognition.interimResults = true; // é€”ä¸­çµŒéã‚’è¡¨ç¤º

            recognition.onresult = (event) => {
                let finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript + '\n';
                    } else {
                        // é€”ä¸­çµŒéï¼ˆè–„ãè¡¨ç¤ºã™ã‚‹ãªã©å¯èƒ½ã ãŒä»Šå›ã¯å˜ç´”çµåˆï¼‰
                        // finalTranscript += event.results[i][0].transcript;
                    }
                }
                // æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿½è¨˜ã§ã¯ãªãã€å¸¸ã«æœ€æ–°ã®èªè­˜çµæœå…¨ä½“ã‚’æç”»ã™ã‚‹ç°¡æ˜“å®Ÿè£…
                // (é•·ã„ä¼šè©±ã®å ´åˆã¯è¿½è¨˜å‹ã«ã™ã‚‹ã®ãŒãƒ™ã‚¿ãƒ¼)
                const currentText = Array.from(event.results)
                    .map(result => result[0].transcript).join('');
                transcriptEl.textContent = currentText;
                transcriptEl.scrollTop = transcriptEl.scrollHeight;
            };

            recognition.onerror = (event) => {
                console.error("Speech API Error:", event.error);
            };

            // éŒ²éŸ³ãŒæ­¢ã¾ã£ãŸã‚‰è‡ªå‹•å†é–‹ï¼ˆã‚¹ãƒãƒ›å¯¾ç­–ï¼‰
            recognition.onend = () => {
                if (isRecording) recognition.start();
            };

            recognition.start();

            // UIæ›´æ–°
            isRecording = true;
            statusEl.classList.remove('hidden');
            recordBtn.disabled = true;
            recordBtn.classList.replace('bg-red-500', 'bg-gray-300');
            stopBtn.disabled = false;
            stopBtn.classList.replace('bg-gray-300', 'bg-blue-600');
            stopBtn.classList.replace('text-gray-500', 'text-white');

        } catch (err) {
            console.error("Error:", err);
            alert("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚");
        }
    }

    // --- ãƒ¡ã‚¤ãƒ³å‡¦ç†: éŒ²éŸ³åœæ­¢ã¨å‡¦ç† ---
    function stopRecording() {
        if (!isRecording) return;
        isRecording = false;

        // æ–‡å­—èµ·ã“ã—åœæ­¢
        recognition.stop();
        
        // éŒ²éŸ³åœæ­¢ -> ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç™ºç«
        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); // Chromeç­‰ã¯webm
            
            // ç„¡éŸ³å‰Šé™¤å‡¦ç†ã‚’å®Ÿè¡Œ
            const processedUrl = await processSilence(audioBlob);
            
            // ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ã‚»ãƒƒãƒˆ
            audioPlayer.src = processedUrl;
            playerArea.classList.remove('hidden');
        };
        mediaRecorder.stop();

        // UIãƒªã‚»ãƒƒãƒˆ
        statusEl.classList.add('hidden');
        recordBtn.disabled = false;
        recordBtn.classList.replace('bg-gray-300', 'bg-red-500');
        stopBtn.disabled = true;
        stopBtn.classList.replace('bg-blue-600', 'bg-gray-300');
        stopBtn.classList.replace('text-white', 'text-gray-500');
    }

    // --- ç„¡éŸ³å‰Šé™¤ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (Web Audio API) ---
    async function processSilence(blob) {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        const rawData = audioBuffer.getChannelData(0); // ãƒ¢ãƒãƒ©ãƒ«æƒ³å®š
        const sampleRate = audioBuffer.sampleRate;
        
        // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
        const threshold = 0.02; // éŸ³é‡é–¾å€¤ (0.0~1.0)
        const minSilenceDuration = 0.5; // ã“ã®ç§’æ•°ä»¥ä¸Šã®ç„¡éŸ³ã‚’ã‚«ãƒƒãƒˆ
        const padding = 0.2; // éŸ³å£°ã®å‰å¾Œã«æ®‹ã™ä½™ç™½(ç§’)

        // æœ‰éŸ³åŒºé–“ã‚’æŠ½å‡º
        const chunks = [];
        let isSpeaking = false;
        let startIndex = 0;
        const silenceSamples = minSilenceDuration * sampleRate;
        const paddingSamples = padding * sampleRate;

        // ç°¡æ˜“çš„ãªç„¡éŸ³æ¤œçŸ¥ãƒ«ãƒ¼ãƒ—
        // å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã§ã¯RMSï¼ˆäºŒä¹—å¹³å‡å¹³æ–¹æ ¹ï¼‰ã‚’ä½¿ã†ã®ãŒç²¾åº¦é«˜ã„ãŒã€ã“ã“ã§ã¯æŒ¯å¹…ã®çµ¶å¯¾å€¤ã§ç°¡æ˜“åˆ¤å®š
        let lastVoiceIndex = 0;
        
        // æœ‰éŸ³ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        let activeIndices = [];
        
        for (let i = 0; i < rawData.length; i++) {
            if (Math.abs(rawData[i]) > threshold) {
                // æœ‰éŸ³
                // å‰å¾Œã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’å«ã‚ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨˜éŒ²
                let start = Math.max(0, i - paddingSamples);
                let end = Math.min(rawData.length, i + paddingSamples);
                activeIndices.push([start, end]);
                
                // å‡¦ç†é«˜é€ŸåŒ–ã®ãŸã‚å°‘ã—ã‚¹ã‚­ãƒƒãƒ—
                i += 100; 
            }
        }

        // é‡è¤‡ã™ã‚‹åŒºé–“ã‚’ãƒãƒ¼ã‚¸
        if (activeIndices.length === 0) return URL.createObjectURL(blob); // ãšã£ã¨ç„¡éŸ³ãªã‚‰ãã®ã¾ã¾è¿”ã™

        let merged = [];
        let current = activeIndices[0];

        for (let i = 1; i < activeIndices.length; i++) {
            if (activeIndices[i][0] < current[1]) {
                current[1] = Math.max(current[1], activeIndices[i][1]);
            } else {
                merged.push(current);
                current = activeIndices[i];
            }
        }
        merged.push(current);

        // ãƒãƒ¼ã‚¸ã•ã‚ŒãŸåŒºé–“ã‹ã‚‰æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
        const totalLength = merged.reduce((acc, val) => acc + (val[1] - val[0]), 0);
        const newBuffer = audioContext.createBuffer(1, totalLength, sampleRate);
        const newData = newBuffer.getChannelData(0);

        let offset = 0;
        merged.forEach(range => {
            const length = range[1] - range[0];
            newData.set(rawData.subarray(range[0], range[1]), offset);
            offset += length;
        });

        return bufferToWave(newBuffer, totalLength);
    }

    // AudioBufferã‚’WAVå½¢å¼ã®Blob URLã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    function bufferToWave(abuffer, len) {
        let numOfChan = abuffer.numberOfChannels,
            length = len * numOfChan * 2 + 44,
            buffer = new ArrayBuffer(length),
            view = new DataView(buffer),
            channels = [], i, sample,
            offset = 0,
            pos = 0;

        // WAVãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿
        setUint32(0x46464952); // "RIFF"
        setUint32(length - 8); // file length - 8
        setUint32(0x45564157); // "WAVE"

        setUint32(0x20746d66); // "fmt " chunk
        setUint32(16); // length = 16
        setUint16(1); // PCM (uncompressed)
        setUint16(numOfChan);
        setUint32(abuffer.sampleRate);
        setUint32(abuffer.sampleRate * 2 * numOfChan); // avg. bytes/sec
        setUint16(numOfChan * 2); // block-align
        setUint16(16); // 16-bit (hardcoded in this demo)

        setUint32(0x61746164); // "data" - chunk
        setUint32(length - pos - 4); // chunk length

        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ (Interleave)
        for(i = 0; i < abuffer.numberOfChannels; i++)
            channels.push(abuffer.getChannelData(i));

        while(pos < len) {
            for(i = 0; i < numOfChan; i++) {
                // float to 16-bit PCM
                sample = Math.max(-1, Math.min(1, channels[i][pos])); 
                sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767)|0; 
                view.setInt16(44 + offset, sample, true); 
                offset += 2;
            }
            pos++;
        }

        return URL.createObjectURL(new Blob([buffer], {type: "audio/wav"}));

        function setUint16(data) { view.setUint16(pos, data, true); pos += 2; }
        function setUint32(data) { view.setUint32(pos, data, true); pos += 4; }
    }
</script>
</body>
</html>
