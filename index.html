<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Post-Transcription</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { touch-action: manipulation; font-family: sans-serif; }
    </style>
</head>
<body class="bg-slate-900 h-screen flex flex-col p-4 text-slate-100">

    <header class="mb-4 text-center">
        <h1 class="text-xl font-bold text-white">録音後 AI文字起こし</h1>
        <p class="text-xs text-slate-400 mt-1">
            録音 → 無音カット → AI解析<br>
            <span class="text-yellow-500">※初回はモデル(40MB)をDLします</span>
        </p>
    </header>

    <div id="statusArea" class="bg-slate-800 p-2 rounded mb-2 text-xs font-mono h-24 overflow-y-auto border border-slate-700">
        <div class="text-blue-400">[System] 準備完了</div>
    </div>

    <div class="flex-grow bg-white rounded-lg p-3 mb-4 overflow-y-auto relative min-h-[150px] text-slate-800">
        <div id="loadingIndicator" class="hidden absolute inset-0 bg-white/90 flex flex-col items-center justify-center z-10">
            <div class="animate-spin h-8 w-8 border-4 border-blue-500 border-t-transparent rounded-full mb-2"></div>
            <p class="text-xs font-bold text-blue-600" id="progressText">AI処理中...</p>
        </div>
        <p id="transcript" class="text-base leading-relaxed whitespace-pre-wrap">ここに結果が表示されます。</p>
    </div>

    <div id="playerArea" class="hidden mb-4 bg-slate-800 p-3 rounded border border-slate-700">
        <div class="flex justify-between items-end mb-2">
            <p class="text-xs text-blue-300 font-bold">無音カット済み音声:</p>
            <a id="downloadLink" class="text-xs text-blue-400 underline">保存</a>
        </div>
        <audio id="audioPlayer" controls class="w-full h-8"></audio>
    </div>

    <div class="grid grid-cols-2 gap-4 pb-2">
        <button id="recordBtn" class="bg-red-600 active:bg-red-700 text-white font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center">
            <span>録音開始</span>
        </button>
        <button id="stopBtn" disabled class="bg-slate-600 text-slate-400 font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center">
            <span>停止＆解析</span>
        </button>
    </div>

<script type="module">
    // CDNからTransformers.jsをインポート
    import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.14.0';

    // ローカルモデルの検索を無効化（CDNのみ使用）
    env.allowLocalModels = false;
    env.useBrowserCache = true;

    // --- 変数 ---
    let transcriber = null; // AIモデルインスタンス
    let mediaRecorder = null;
    let audioChunks = [];
    let isRecording = false;

    // --- UI要素 ---
    const recordBtn = document.getElementById('recordBtn');
    const stopBtn = document.getElementById('stopBtn');
    const transcriptEl = document.getElementById('transcript');
    const statusArea = document.getElementById('statusArea');
    const playerArea = document.getElementById('playerArea');
    const audioPlayer = document.getElementById('audioPlayer');
    const downloadLink = document.getElementById('downloadLink');
    const loadingIndicator = document.getElementById('loadingIndicator');
    const progressText = document.getElementById('progressText');

    // --- ログ機能 ---
    function log(msg) {
        const d = document.createElement('div');
        d.textContent = `> ${msg}`;
        statusArea.appendChild(d);
        statusArea.scrollTop = statusArea.scrollHeight;
    }

    // --- イベント ---
    recordBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);

    // --- 1. AIモデルのロード (初回のみ) ---
    async function loadModel() {
        if (transcriber) return transcriber;

        log("AIモデルをダウンロード中... (約40MB)");
        progressText.textContent = "モデル準備中(初回は長いです)...";
        loadingIndicator.classList.remove('hidden');

        try {
            // 軽量版Whisper (multilingual) をロード
            transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny', {
                progress_callback: (data) => {
                    if (data.status === 'progress') {
                        // ダウンロード進捗を表示
                        const percent = Math.round(data.progress || 0);
                        if(percent % 10 === 0) log(`DL: ${data.file} ${percent}%`);
                    }
                }
            });
            log("AIモデル準備完了！");
        } catch (e) {
            log("モデル読込エラー: " + e.message);
            alert("AIモデルの読み込みに失敗しました。");
        } finally {
            loadingIndicator.classList.add('hidden');
        }
        return transcriber;
    }

    // バックグラウンドでモデル読み込み開始
    setTimeout(loadModel, 1000);


    // --- 2. 録音開始 ---
    async function startRecording() {
        transcriptEl.textContent = "録音中...停止後に解析します。";
        audioChunks = [];
        playerArea.classList.add('hidden');
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
            
            mediaRecorder.ondataavailable = e => {
                if(e.data.size > 0) audioChunks.push(e.data);
            };
            
            mediaRecorder.start();
            isRecording = true;
            toggleButtons(true);
            log("録音開始");
            
        } catch (e) {
            log("マイクエラー: " + e.message);
            alert("マイクへのアクセスを許可してください");
        }
    }

    // --- 3. 録音停止 ＆ 処理フロー ---
    function stopRecording() {
        if (!isRecording) return;
        isRecording = false;
        log("録音終了。処理を開始します...");
        
        mediaRecorder.onstop = async () => {
            toggleButtons(false);
            loadingIndicator.classList.remove('hidden');
            progressText.textContent = "音声処理中...";

            try {
                // A. Blob作成
                const blob = new Blob(audioChunks, { type: 'audio/webm' });
                
                // B. AudioContextでデコード & 無音削除
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // C. 無音削除実行
                const { processedBuffer, wavUrl } = await removeSilence(audioBuffer, audioContext);
                
                // プレイヤー更新
                audioPlayer.src = wavUrl;
                downloadLink.href = wavUrl;
                downloadLink.download = `rec_processed.wav`;
                playerArea.classList.remove('hidden');
                
                // D. AI文字起こし実行
                log("AIによる文字起こし開始...");
                progressText.textContent = "AI解析中...";
                
                // モデルがまだなら待つ
                const pipe = await loadModel();
                
                // AudioBufferからPCMデータ(Float32Array)を取得
                const audioData = processedBuffer.getChannelData(0);
                
                // 推論実行 (日本語指定)
                const output = await pipe(audioData, {
                    language: 'japanese',
                    task: 'transcribe',
                    chunk_length_s: 30,
                    stride_length_s: 5
                });
                
                // 結果表示
                transcriptEl.textContent = output.text;
                log("完了しました");

            } catch (e) {
                log("処理エラー: " + e.message);
                console.error(e);
                transcriptEl.textContent = "エラーが発生しました: " + e.message;
            } finally {
                loadingIndicator.classList.add('hidden');
            }
        };

        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }


    // --- 無音削除ロジック (Web Audio API) ---
    async function removeSilence(audioBuffer, context) {
        const rawData = audioBuffer.getChannelData(0);
        const sampleRate = audioBuffer.sampleRate;
        const threshold = 0.05; 
        const padding = Math.floor(0.2 * sampleRate);

        // 有音区間検出
        let ranges = [];
        for (let i = 0; i < rawData.length; i++) {
            if (Math.abs(rawData[i]) > threshold) {
                let start = Math.max(0, i - padding);
                let end = Math.min(rawData.length, i + padding);
                ranges.push([start, end]);
                i = end; // 少しスキップ
            }
        }

        if (ranges.length === 0) {
            // 全部無音の場合
            return { processedBuffer: audioBuffer, wavUrl: bufferToWave(audioBuffer, rawData.length) };
        }

        // マージ
        let merged = [ranges[0]];
        for (let i = 1; i < ranges.length; i++) {
            let last = merged[merged.length - 1];
            let current = ranges[i];
            if (current[0] < last[1]) {
                last[1] = Math.max(last[1], current[1]);
            } else {
                merged.push(current);
            }
        }

        // 新しいバッファ作成
        let totalLen = merged.reduce((s, r) => s + (r[1] - r[0]), 0);
        let outBuf = context.createBuffer(1, totalLen, sampleRate);
        let outData = outBuf.getChannelData(0);
        
        let offset = 0;
        merged.forEach(r => {
            outData.set(rawData.subarray(r[0], r[1]), offset);
            offset += (r[1] - r[0]);
        });

        const wavUrl = bufferToWave(outBuf, totalLen);
        return { processedBuffer: outBuf, wavUrl: wavUrl };
    }

    function bufferToWave(abuffer, len) {
        let length = len * 2 + 44;
        let buffer = new ArrayBuffer(length);
        let view = new DataView(buffer);
        let pos = 0;
        const setUint16 = (d) => { view.setUint16(pos, d, true); pos+=2; };
        const setUint32 = (d) => { view.setUint32(pos, d, true); pos+=4; };

        setUint32(0x46464952); setUint32(length-8); setUint32(0x45564157);
        setUint32(0x20746d66); setUint32(16); setUint16(1); setUint16(1);
        setUint32(abuffer.sampleRate); setUint32(abuffer.sampleRate*2);
        setUint16(2); setUint16(16); setUint32(0x61746164); setUint32(length-pos-4);

        let ch = abuffer.getChannelData(0);
        let offset = 44;
        for (let i=0; i<len; i++) {
            let s = Math.max(-1, Math.min(1, ch[i]));
            s = (s < 0 ? s * 0x8000 : s * 0x7FFF)|0;
            view.setInt16(offset, s, true);
            offset+=2;
        }
        return URL.createObjectURL(new Blob([buffer], {type: "audio/wav"}));
    }

    function toggleButtons(rec) {
        recordBtn.disabled = rec;
        recordBtn.className = rec ? "bg-slate-700 text-slate-500 font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center" : "bg-red-600 active:bg-red-700 text-white font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center";
        stopBtn.disabled = !rec;
        stopBtn.className = !rec ? "bg-slate-600 text-slate-500 font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center" : "bg-blue-600 active:bg-blue-700 text-white font-bold py-4 rounded-xl shadow-lg flex flex-col items-center justify-center";
    }
</script>
</body>
</html>
